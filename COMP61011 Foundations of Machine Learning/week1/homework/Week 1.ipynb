{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 61011 Week 1\n",
    "\n",
    "## Level 0\n",
    "You should find the exercises in this level very simple to complete. All of the of the information required to complete these exercises can be found at www.learnpython.org. The cells below provide some skeleton code and some additional questions, but you should attempt to complete these exercises without using the skeleton code first.\n",
    "\n",
    "If you **do** need to refer to the skeleton code, you will struggle with the remainder of the labs. In this case, we strongly advise going through the entire tutorial at www.learnpython.org before proceeding to Level 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a loop to sum the even numbers from 1 to 100\n",
    "Before looking at the code below, think about whether a FOR loop or WHILE loop is more appropriate for this problem.\n",
    "\n",
    "Type your answer here before revealing the answer below\n",
    "\n",
    "Answer: Both loops can be used to complete the task. In general, a FOR loop should be used when the number of iterations (times around the loop) is pre-determined. This is the case here, when we know, before entering the loop, that we will loop through 50 even numbers\n",
    "\n",
    "A WHILE loop is often slightly slower, as it needs to check a Boolean condition each time the loop is executed. Later in the course, we will see that WHILE loops are necessary when we have a stopping criterion for an iterative algorithm.\n",
    "\n",
    "The code below is a skeleton. Replace the 'xx's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(0, 100, 2):\n",
    "    count = count + i\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: count = 2450\n",
    "\n",
    "### sum the even numbers 1 to 100 without a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450\n"
     ]
    }
   ],
   "source": [
    "vec = range(0,100,2)\n",
    "count = sum(vec)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: count = 2450\n",
    "\n",
    "### Write a function to return the sum of its arguments and call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n",
      "530\n"
     ]
    }
   ],
   "source": [
    "def addXY(a,b):\n",
    "    return a+b\n",
    "    \n",
    "# call function below:\n",
    "print(addXY(3,2))\n",
    "print(addXY(1,-1))\n",
    "print(addXY(500,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 5, 0, 530\n",
    "\n",
    "### Write a function to return the sum of all the even numbers up to a given number, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450\n"
     ]
    }
   ],
   "source": [
    "def sumEven(x):\n",
    "    count = 0\n",
    "    vec = range(0,x,2)\n",
    "    return(sum(vec))\n",
    "\n",
    "print(sumEven(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 2450\n",
    "\n",
    "## Level 1\n",
    "\n",
    "Work through the tutorial at http://scikit-learn.org/stable/tutorial/basic/tutorial.html, if you are not already familiar with the scikit library\n",
    "\n",
    "You should start a new jupyter notebook (or create a new Python script within the Spyder IDE, if you prefer) and copy and paste the code snippets as required. For the moment, you do not need to understand what the SVC function does - you may treat it as a 'black box'. This will become clear when we learn about Support Vector Machines.\n",
    "\n",
    "It is critically important that you understand how models are first created, and then trained using the *fit* function.\n",
    "\n",
    "You should also understand that the trained model is **not** saved, unless you use pickle. This is all covered in the tutorial.\n",
    "\n",
    "### Use SKlearn to load a dataset, and display it on the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5     6   7   8   9   10\n",
       "0  1000025   5   1   1   1   2   1.0   3   1   1   2\n",
       "1  1002945   5   4   4   5   7  10.0   3   2   1   2\n",
       "2  1015425   3   1   1   1   2   2.0   3   1   1   2\n",
       "3  1016277   6   8   8   1   3   4.0   3   7   1   2\n",
       "4  1017023   4   1   1   3   2   1.0   3   1   1   2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SKlearn has a set of built-in datasets. The way to load these is given in the\n",
    "# scikit tutorial. In general, you will apply machnine learning techniques to\n",
    "# datasets that are not included. The skeleton code below takes you through the\n",
    "# process of importing an external data set in csv format.\n",
    "\n",
    "\n",
    "# 1.) first, download the breast cancer data set from here: https://archive.ics.uci.edu/m.l/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "# n.b. the data is in the file breast-cancer-wisconsin.data. If you want to view it in a \n",
    "# text editor/ excel, then you will need to rename the file as a .csv\n",
    "\n",
    "# 2.) import the data - make sure you understand what the options (header=None, na_values=['?']) are doing\n",
    "import pandas as pd #import the pandas library for data manipulation\n",
    "cancer_data = pd.read_csv(\"breast-cancer-wisconsin.data.csv\", header=None, na_values=['?'])\n",
    "\n",
    "# 3.) Display the first few lines of the dataset\n",
    "cancer_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     4.417740\n",
       "2     3.134478\n",
       "3     3.207439\n",
       "4     2.806867\n",
       "5     3.216023\n",
       "6     3.544656\n",
       "7     3.437768\n",
       "8     2.866953\n",
       "9     1.589413\n",
       "10    2.689557\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.) generate summary statistics for the dataset\n",
    "# n.b. column 0 is a user id (uninformative), so we should ignore it from here\n",
    "\n",
    "cancer_data = cancer_data.loc[:,1:] # make sure you understand what this line is doing\n",
    "\n",
    "#calculate mean\n",
    "cancer_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2.815741\n",
       "2     3.051459\n",
       "3     2.971913\n",
       "4     2.855379\n",
       "5     2.214300\n",
       "6     3.643857\n",
       "7     2.438364\n",
       "8     3.053634\n",
       "9     1.715078\n",
       "10    0.951273\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate standard deviation\n",
    "cancer_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa6170a36d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.) Plot two of the feature variables\n",
    "# first, we need to import a plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(cancer_data.loc[:,1],cancer_data.loc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa6170f61f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(cancer_data.loc[:,7],cancer_data.loc[:,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the previous two plots, you should be able to explain, in words, what is being plotted. Which of the two plots is more useful, and why?\n",
    "\n",
    "### Use SKlearn to build a logistic regression model, then to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#remove any rows with missing data\n",
    "cancer_data = cancer_data.dropna()\n",
    "\n",
    "# split the data set up into features (columns 1 to 9) and labels (column 10). Convert the data from a dataframe structure\n",
    "# into an array. Note that we have used a dataframe now as it is easier to manipulate a dataset. However, the sklearn library\n",
    "# requires inputs to be arrays.\n",
    "features = cancer_data.loc[:,:9].to_numpy()\n",
    "labels = cancer_data.loc[:,10].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into testing and training\n",
    "In Machine Learning, we want to estimate whether our trained model is generalisable to new data. To do this, we typically split up our whole data set into a training set and a testing set (there is no fixed rule on the percentage of each set - whatever seems reasonable).\n",
    "\n",
    "For some algorithms, we may choose to divide the training set into two: a training set and a validation set. This occurs when we want to adjust some model parameters, and will be introduced later in the course.\n",
    "\n",
    "We note that splitting the data in this way may not be optimal - by luck, we might split the data in such a way that the model performs better than expected (for instance, if the test set happens to contain lots of easy examples to classify). A more rigorous approach is to use a method called *cross-validation*. In this method, we use a different sample to create a different training set and test set multiple times. This gives us a range of similar, but slightly different models, from which we can calculate confidence intervals on our predictions.\n",
    "\n",
    "Below, we divide the dataset into a 70% training set and a 30% test set, before training a logistic regression on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state = 0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the way that models are created and trained in sklearn. In all cases, a model is first created, and then fitted using the training data. Once the model has been trained, we can use it to make predictions, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2,\n",
       "       4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 2,\n",
       "       2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2,\n",
       "       4, 4, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 4, 2, 2,\n",
       "       4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2,\n",
       "       4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2,\n",
       "       4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2,\n",
       "       2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2,\n",
       "       4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 2,\n",
       "       2, 2, 4, 4, 4, 2, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the predict step gives us the raw predictions, but we are really interested to know whether the prediction matches the actual labels, Y_test. We can summarise how well the predictions match reality using various metrics (including sensitivity, specificity, and f1 score). For now, we will use % correct (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9560975609756097"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the testing performance of a logistic regression for different learning rates\n",
    "The standard logistic regression model in sklearn uses the *liblinear* solver to learn the model weights. This solver does not require a learning rate. In contrast, the stochastic gradient descent algorithm requires a learning rate. The learning rate tells the computer how much the model weights can change at each iteration of the algorithm. If the learning rate is too large, it can overshoot the true solution. If it is too small, then it takes a long time to converge to the solution.\n",
    "\n",
    "In this case, we set the algorithm to end when either there has been 1000 iterations (epochs), or if the error does not change by more than 1e-3 between iterations. The first condition is to prevent us waiting all day. The second condition is one way of determining that the algorithm has converged to a solution. This combination of end points means that in some cases, we might stop before the algorithm has finished converging to the solution.\n",
    "\n",
    "To examine this effect, edit the code sample below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9658536585365853"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit logistic regression with different learning rates\n",
    "#  the parameter solver sets the method by which the likelihood is maximised - other choices include 'newton-cg' i.e. newton conjugate gradient descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#put FOR loop round this to change the learning rate.\n",
    "rate = 1\n",
    "clf = SGDClassifier(max_iter = 1000, tol = 1e-3, random_state=0, learning_rate='constant', eta0=rate)\n",
    "clf.fit(X_test, y_test)\n",
    "out = clf.predict(X_test)\n",
    "accuracy_score(y_test,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
