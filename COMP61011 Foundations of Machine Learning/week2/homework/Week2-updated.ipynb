{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 61011 Week 2\n",
    "\n",
    "Over the next week: try to do all of Level 1, and some of Level 2. Skeleton code is provide for the Level 1 targets, below.\n",
    "\n",
    "In addition, read through and understand the Jupyter notebooks on Logistic Regression, Perceptron, and Machine Learning Training\n",
    "\n",
    "## Level 1\n",
    "Rather than importing data directly, we will use the data sets built in to sklearn for these tasks. This saves us having to download and convert csv files.\n",
    "\n",
    "### Plot train/test errors of a logistic regression, as the number of epochs increase\n",
    "Note that the code below will throw a series of warnings, because we are stopping the logistic regression before it has fully finished training.\n",
    "\n",
    "What is the effect of changing the train/test split?\n",
    "What is the effect of changing the number of epochs?\n",
    "What is the effect of changing the solver?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the iris data set. Information on the data set here: https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.pyplot import plot\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "epochs = 30;\n",
    "training_acc = [0] * (epochs-1)\n",
    "test_acc = [0] * (epochs-1)\n",
    "\n",
    "for i in range(1,epochs):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=i)\n",
    "    # TODO: train the model\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    training_acc[i-1] = accuracy_score(y_train,clf.predict(X_train))\n",
    "    test_acc[i-1] = accuracy_score(y_test,clf.predict(X_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc9f93de2e0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(training_acc)\n",
    "plot(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the train/test error over 10 repeats, shuffling the data each time, with error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc mean 0.706667\n",
      "Test acc mean 0.748000\n",
      "(0.5064929379987196, 0.9068403953346139)\n",
      "(0.5515960900243904, 0.9444039099756096)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np,scipy.stats as st\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.pyplot import plot\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "training_acc = [0] * (10)\n",
    "test_acc = [0] * (10)\n",
    "\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5)\n",
    "    # TODO: train the model\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    # TODO: store the training accuracy\n",
    "    training_acc[i] = accuracy_score(y_train,clf.predict(X_train))\n",
    "    # TODO: store the test accuracy\n",
    "    test_acc[i] = accuracy_score(y_test,clf.predict(X_test))\n",
    "    \n",
    "# get the mean training_acc and test_acc\n",
    "training_acc_mean = np.mean(training_acc)\n",
    "test_acc_mean = np.mean(test_acc_mean)\n",
    "print(\"Training acc mean %f\" % training_acc_mean)\n",
    "print(\"Test acc mean %f\"% test_acc_mean)\n",
    "# generate error bars (either max/min, or the 95% confidence intervals)\n",
    "ci_train = st.t.interval(0.95,len(training_acc)-1,loc=training_acc_mean,scale=st.sem(training_acc))\n",
    "ci_test = st.t.interval(0.95,len(test_acc)-1,loc=test_acc_mean,scale=st.sem(test_acc))\n",
    "print(ci_t)\n",
    "print(ci_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the 5-fold cross validation error of a logistic regression, accounting for any sources of variance in the performance\n",
    "We now apply the cross validation. If you are not sure what cross-validation is, or why it is used, please refer to the Machine Learning Training Jupyter notebook and the course textbook.\n",
    "\n",
    "\n",
    "Note that, before training the model, we have scaled all the features to have zero mean and unit (one) variance. Although this is not always strictly necessary, it is often for methods that use gradient descent, which may otherwise end up prioritising features with a large range of values.\n",
    "\n",
    "Strictly speaking, scaling should be computed on the training set only, to prevent information leakage between the training and test sets (but we have not done that here)\n",
    "\n",
    "Also note that in the LogisticRegression model, we have set random_state = 0. This ensures that the random number used to in the algorithm solver is consistent between runs (i.e. removing a source of variance). In this case, where the loss function is convex and the algorithms converge, so it should not make any difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9583333333333334\n",
      "confidence interval = 0.10330107023216707\n"
     ]
    }
   ],
   "source": [
    "# apply cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "features_scaled = preprocessing.scale(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2)\n",
    "\n",
    "# TODO: create the model\n",
    "model = LogisticRegression(max_iter = 200)\n",
    "# TODO: train the model\n",
    "###############\n",
    "scores=cross_val_score(model, X_train, y_train, cv=5)\n",
    "# TODO: test the model\n",
    "#y_pred = model.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "\n",
    "accuracy = np.mean(scores)\n",
    "print(\"accuracy = \" + str(accuracy))\n",
    "std_err = np.std(scores) * 1.96\n",
    "print(\"confidence interval = \" + str(std_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should understand what a confidence interval is, how it is derived from the Standard Error, and how the standard error differs from the standard deviation.\n",
    "\n",
    "### Calculate the leave-one-out cross validation error of a logistic regression mode\n",
    "In leave one out cross validation (LOO-CV), the model is trained on N-1 of N data points, and the tested on the remaining point. This procedure is repeated N times for a different set of N-1 points each time. The method is useful when the number of training instances is very limited, but may provide overly optimistic results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# apply LOO cross validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "model = LogisticRegression(random_state = 0, max_iter = 1000)\n",
    "loo = LeaveOneOut()\n",
    "correct = 0\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    model.fit(X[train_idx], y[train_idx])\n",
    "    # print(model.predict(X[test_idx]))\n",
    "    if model.predict(X[test_idx]) == y[test_idx]:\n",
    "        correct = correct + 1\n",
    "        \n",
    "acc = correct / len(X)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2\n",
    "\n",
    "Below are a few hints for the level 2 tasks\n",
    "\n",
    "### Investigate the sensitivity of the logistic regression to the amount of training data examples it sees\n",
    "In other words, how much does the logistic regression decision boundary (defined by the weight parameters) change, given the amount of training data.\n",
    "\n",
    "One way to assess the change in the logistic regression model is to examine the changes in the weight parameters. These can be accessed using the coef_ method (e.g. clf.coef_).\n",
    "\n",
    "An alternative way of investigating the sensitivity of the model is to see how accurate it is as you increase/decrease the training data set.\n",
    "\n",
    "\n",
    "### Investigate the idea of a 'momentum' parameter and implement it\n",
    "\n",
    "### Investigate alternative to gradient descent\n",
    "Try adjusting the 'solver' parameter for the logisticRegression model, and comparing the (i) number of epochs required for convergence (ii) training time. Note that these may be dependent on the problem that you are trying to solve, so you sohuld try multiple data sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
